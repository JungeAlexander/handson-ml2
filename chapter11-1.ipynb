{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3ktAy_lS1M4N"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1SSezsQI7HH"
   },
   "source": [
    "# Chapter 11. Training Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oti2elcdI8TV",
    "outputId": "c83da004-3512-4176-b1f1-3f9f21515196"
   },
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rU5GJrMcvbjx"
   },
   "outputs": [],
   "source": [
    "# TODO this?\n",
    "#x_train_full = x_train_full / 255.0\n",
    "#x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lbhHWbMjvhn_"
   },
   "outputs": [],
   "source": [
    "x_val = x_train_full[:5000]\n",
    "y_val = y_train_full[:5000]\n",
    "x_train = x_train_full[5000:]\n",
    "y_train = y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part a and b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyLHg-zAzxeW",
    "outputId": "9add5623-3b78-4e7c-f07e-35ce08dfca14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   1/1407 [..............................] - ETA: 58:28 - loss: 165.9660 - accuracy: 0.0625WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0057s vs `on_train_batch_end` time: 0.0122s). Check your callbacks.\n",
      "1407/1407 [==============================] - 11s 6ms/step - loss: 2.8284 - accuracy: 0.2020 - val_loss: 2.0970 - val_accuracy: 0.2400 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.9397 - accuracy: 0.2820 - val_loss: 2.4095 - val_accuracy: 0.1984 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8631 - accuracy: 0.3174 - val_loss: 1.9118 - val_accuracy: 0.2940 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.8091 - accuracy: 0.3408 - val_loss: 2.3432 - val_accuracy: 0.2238 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7660 - accuracy: 0.3582 - val_loss: 1.7345 - val_accuracy: 0.3714 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.7167 - accuracy: 0.3804 - val_loss: 1.7449 - val_accuracy: 0.3778 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6790 - accuracy: 0.3931 - val_loss: 1.6712 - val_accuracy: 0.3918 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6477 - accuracy: 0.4069 - val_loss: 1.6955 - val_accuracy: 0.3868 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.6200 - accuracy: 0.4209 - val_loss: 1.6504 - val_accuracy: 0.4098 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5970 - accuracy: 0.4256 - val_loss: 1.6518 - val_accuracy: 0.4012 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5819 - accuracy: 0.4315 - val_loss: 1.7152 - val_accuracy: 0.3790 - lr: 3.0000e-04\n",
      "Epoch 12/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5613 - accuracy: 0.4400 - val_loss: 1.6063 - val_accuracy: 0.4252 - lr: 3.0000e-04\n",
      "Epoch 13/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5400 - accuracy: 0.4483 - val_loss: 1.6247 - val_accuracy: 0.4146 - lr: 3.0000e-04\n",
      "Epoch 14/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5296 - accuracy: 0.4517 - val_loss: 1.5941 - val_accuracy: 0.4308 - lr: 3.0000e-04\n",
      "Epoch 15/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5176 - accuracy: 0.4574 - val_loss: 1.6001 - val_accuracy: 0.4222 - lr: 3.0000e-04\n",
      "Epoch 16/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.5009 - accuracy: 0.4654 - val_loss: 1.5537 - val_accuracy: 0.4460 - lr: 3.0000e-04\n",
      "Epoch 17/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4872 - accuracy: 0.4673 - val_loss: 1.5551 - val_accuracy: 0.4484 - lr: 3.0000e-04\n",
      "Epoch 18/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4752 - accuracy: 0.4728 - val_loss: 1.5266 - val_accuracy: 0.4628 - lr: 3.0000e-04\n",
      "Epoch 19/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4662 - accuracy: 0.4743 - val_loss: 1.5712 - val_accuracy: 0.4342 - lr: 3.0000e-04\n",
      "Epoch 20/20\n",
      "1407/1407 [==============================] - 8s 6ms/step - loss: 1.4536 - accuracy: 0.4816 - val_loss: 1.5573 - val_accuracy: 0.4534 - lr: 3.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ba1ead0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=(32, 32, 3)))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=3e-4)\n",
    "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
    "run_index = 5 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_no_norm_{:03d}\".format(run_index))\n",
    "#tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "class LearningRateTensorBoard(keras.callbacks.TensorBoard):\n",
    "    # add other arguments to __init__ if you need\n",
    "    def __init__(self, log_dir, **kwargs):\n",
    "        super().__init__(log_dir=log_dir, **kwargs)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs.update({'lr': keras.backend.eval(self.model.optimizer.lr)})\n",
    "        super().on_epoch_end(epoch, logs)\n",
    "tensorboard_cb = LearningRateTensorBoard(run_logdir)\n",
    "\n",
    "callbacks = [\n",
    "    #early_stopping_cb,\n",
    "    model_checkpoint_cb,\n",
    "    tensorboard_cb]\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20,\n",
    "          validation_data=(x_val, y_val),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "chapter11-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
